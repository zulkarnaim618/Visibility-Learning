{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10950169,"sourceType":"datasetVersion","datasetId":6811285},{"sourceId":10950540,"sourceType":"datasetVersion","datasetId":6811556},{"sourceId":278349,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":238424,"modelId":260092}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nimport numpy as np\nfrom sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, confusion_matrix\nimport matplotlib.pyplot as plt\nfrom typing import Optional, Tuple, List, Dict\nimport time\nfrom tqdm import tqdm\n\nclass TransformerEncoderLayer(nn.Module):\n    \"\"\"\n    A single transformer encoder layer.\n    \"\"\"\n    def __init__(\n        self,\n        d_model: int,\n        nhead: int,\n        dim_feedforward: int = 2048,\n        dropout: float = 0.1,\n        activation: str = \"relu\",\n        layer_norm_eps: float = 1e-5,\n    ):\n        super().__init__()\n        self.self_attn = nn.MultiheadAttention(d_model, nhead, dropout=dropout, batch_first=True)\n        \n        # Feed forward network\n        self.linear1 = nn.Linear(d_model, dim_feedforward)\n        self.dropout = nn.Dropout(dropout)\n        self.linear2 = nn.Linear(dim_feedforward, d_model)\n        \n        # Layer normalization\n        self.norm1 = nn.LayerNorm(d_model, eps=layer_norm_eps)\n        self.norm2 = nn.LayerNorm(d_model, eps=layer_norm_eps)\n        self.dropout1 = nn.Dropout(dropout)\n        self.dropout2 = nn.Dropout(dropout)\n        \n        # Activation function\n        self.activation = _get_activation_fn(activation)\n        \n    def forward(self, src, src_mask=None, src_key_padding_mask=None):\n        # Multi-head attention block\n        src2 = self.norm1(src)\n        src2, _ = self.self_attn(src2, src2, src2, attn_mask=src_mask, \n                                key_padding_mask=src_key_padding_mask)\n        src = src + self.dropout1(src2)\n        \n        # Feed forward block\n        src2 = self.norm2(src)\n        src2 = self.linear2(self.dropout(self.activation(self.linear1(src2))))\n        src = src + self.dropout2(src2)\n        \n        return src\n\n\nclass TransformerEncoder(nn.Module):\n    \"\"\"\n    Full transformer encoder with configurable number of layers.\n    \"\"\"\n    def __init__(\n        self,\n        d_model: int,\n        nhead: int,\n        num_layers: int,\n        dim_feedforward: int = 2048,\n        dropout: float = 0.1,\n        activation: str = \"relu\",\n        layer_norm_eps: float = 1e-5,\n    ):\n        super().__init__()\n        \n        self.layers = nn.ModuleList([\n            TransformerEncoderLayer(\n                d_model=d_model,\n                nhead=nhead,\n                dim_feedforward=dim_feedforward,\n                dropout=dropout,\n                activation=activation,\n                layer_norm_eps=layer_norm_eps\n            )\n            for _ in range(num_layers)\n        ])\n        \n        self.norm = nn.LayerNorm(d_model, eps=layer_norm_eps)\n        \n    def forward(self, src, src_mask=None, src_key_padding_mask=None):\n        output = src\n        \n        for layer in self.layers:\n            output = layer(output, src_mask=src_mask, src_key_padding_mask=src_key_padding_mask)\n            \n        output = self.norm(output)\n        return output\n\n\nclass LineSequenceClassifier(nn.Module):\n    \"\"\"\n    Transformer model for binary classification of 2D line sequences.\n    Each line is represented by 4 numbers (x1, y1, x2, y2).\n    \"\"\"\n    def __init__(\n        self,\n        line_dim: int = 4,  # Dimension of each line (x1, y1, x2, y2)\n        d_model: int = 128, # Embedding dimension\n        nhead: int = 8,\n        num_encoder_layers: int = 4,\n        dim_feedforward: int = 512,\n        dropout: float = 0.1,\n        activation: str = \"relu\",\n        layer_norm_eps: float = 1e-5,\n    ):\n        super().__init__()\n        \n        self.d_model = d_model\n        \n        # Project 4D line features to d_model dimensions\n        self.line_embedding = nn.Linear(line_dim, d_model)\n        \n        # Transformer encoder\n        self.transformer_encoder = TransformerEncoder(\n            d_model=d_model,\n            nhead=nhead,\n            num_layers=num_encoder_layers,\n            dim_feedforward=dim_feedforward,\n            dropout=dropout,\n            activation=activation,\n            layer_norm_eps=layer_norm_eps\n        )\n        \n        # Classification head\n        self.classifier = nn.Sequential(\n            nn.Linear(d_model, 128),\n            nn.ReLU(),\n            nn.Dropout(dropout),\n            nn.Linear(128, 64),\n            nn.ReLU(),\n            nn.Dropout(dropout),\n            nn.Linear(64, 16),\n            nn.ReLU(),\n            nn.Dropout(dropout),\n            nn.Linear(16, 1)\n        )\n        \n    def forward(self, src, src_lengths):\n        # src shape: [batch_size, seq_len, line_dim]\n        batch_size, max_len, _ = src.shape\n        \n        # Create padding mask based on sequence lengths\n        src_key_padding_mask = torch.arange(max_len, device=src.device).expand(batch_size, max_len) >= src_lengths.unsqueeze(1)\n        \n        # Line feature embedding\n        x = self.line_embedding(src)\n        \n        # Transformer encoding\n        encoded = self.transformer_encoder(x, src_key_padding_mask=src_key_padding_mask)\n        \n        # Get the last valid token for each sequence in the batch\n        batch_indices = torch.arange(encoded.size(0), device=encoded.device)\n        last_indices = src_lengths - 1  # Convert to 0-indexed\n        last_hidden = encoded[batch_indices, last_indices]\n        \n        # Binary classification\n        logits = self.classifier(last_hidden).squeeze(-1)\n        return logits\n\n    def predict(self, src, src_lengths):\n        \"\"\"\n        Convenience method that returns binary predictions.\n        \"\"\"\n        logits = self.forward(src, src_lengths)\n        return torch.sigmoid(logits) >= 0.5\n\n\nclass LineSequenceDataset(Dataset):\n    def __init__(self, file_path):\n        self.file_path = file_path\n        self.cache = []  # To store parsed scenes\n        self.samples = []  # To store indices of individual samples\n\n        # Read and parse the file during initialization\n        self._parse_file()\n\n    def _parse_file(self):\n        \"\"\"Reads the file and caches scenes and their queries.\"\"\"\n        with open(self.file_path, 'r') as file:\n            for line_idx, line in enumerate(file):\n                line = line.strip().split()\n\n                # Parse obstacles\n                obstacles = []\n                idx = 0\n                while idx < len(line) and line[idx] != 'q':\n                    x, y, x1, y1 = float(line[idx]), float(line[idx + 1]), float(line[idx + 2]), float(line[idx + 3])\n                    idx += 4\n                    obstacles.append((x, y, x1, y1))\n\n                # Parse queries and labels\n                queries = []\n                while idx < len(line):\n                    if line[idx] == 'q':\n                        idx += 1  # Skip 'q'\n                        x, y, x1, y1, label = float(line[idx]), float(line[idx + 1]), float(line[idx + 2]), float(line[idx + 3]), int(line[idx+4])\n                        idx += 5\n                        queries.append(((x, y, x1, y1), label))\n\n                # Cache the parsed scene\n                scene_idx = len(self.cache)\n                self.cache.append((obstacles, queries))\n\n                # Index individual samples\n                for query_idx in range(len(queries)):\n                    self.samples.append((scene_idx, query_idx))\n\n\n    def __len__(self):\n        \"\"\"Total number of samples (queries).\"\"\"\n        return len(self.samples)\n\n    def __getitem__(self, idx):\n        \"\"\"Returns a single sample: obstacles, query, label, and augmentation orders.\"\"\"\n        scene_idx, query_idx = self.samples[idx]\n        obstacles, queries = self.cache[scene_idx]\n        query, label = queries[query_idx]\n\n        return obstacles + [query], len(obstacles + [query]), label\n    \n\ndef _get_activation_fn(activation):\n    \"\"\"Helper function to get activation function by name.\"\"\"\n    if activation == \"relu\":\n        return F.relu\n    elif activation == \"gelu\":\n        return F.gelu\n    else:\n        raise ValueError(f\"Activation function {activation} not supported\")\n\n\ndef collate_fn(batch):\n    \"\"\"\n    Custom collate function for variable length sequences.\n    \"\"\"\n    sequences, sequence_lengths, labels = zip(*batch)\n    \n    # Find max sequence length in this batch\n    max_len = max(sequence_lengths)\n    \n    # Pad sequences to max_len\n    padded_sequences = []\n    for seq, seq_len in zip(sequences, sequence_lengths):\n        padded_seq = np.zeros((max_len, 4))\n        padded_seq[:seq_len] = seq\n        padded_sequences.append(padded_seq)\n    \n    # Convert to tensors\n    sequences_tensor = torch.tensor(np.array(padded_sequences), dtype=torch.float32)\n    sequence_lengths_tensor = torch.tensor(sequence_lengths, dtype=torch.long)\n    labels_tensor = torch.tensor(labels, dtype=torch.float32)\n    \n    return sequences_tensor, sequence_lengths_tensor, labels_tensor\n\n\ndef calculate_metrics(y_true, y_pred):\n    \"\"\"\n    Calculate classification metrics: accuracy, recall, precision, specificity, and F1 score.\n    Handles cases where precision may be undefined due to no positive predictions.\n    \"\"\"\n    # Convert to numpy arrays if tensors\n    if isinstance(y_true, torch.Tensor):\n        y_true = y_true.cpu().numpy()\n    if isinstance(y_pred, torch.Tensor):\n        y_pred = y_pred.cpu().numpy()\n    \n    # Calculate metrics with zero_division=0 to prevent warnings\n    accuracy = accuracy_score(y_true, y_pred)\n    recall = recall_score(y_true, y_pred, zero_division=0)\n    precision = precision_score(y_true, y_pred, zero_division=0)\n    f1 = f1_score(y_true, y_pred, zero_division=0)\n    \n    # Calculate specificity (true negative rate)\n    if len(y_true) > 0:\n        tn, fp, fn, tp = confusion_matrix(y_true, y_pred, labels=[0, 1]).ravel()\n        specificity = tn / (tn + fp) if (tn + fp) > 0 else 1.0\n    else:\n        specificity = 0.0\n    \n    return {\n        'accuracy': accuracy,\n        'recall': recall,\n        'precision': precision,\n        'specificity': specificity,\n        'f1_score': f1\n    }\n\n\ndef train(model, train_loader, val_loader, criterion, optimizer, device, num_epochs=10, patience=3, resume_from=None):\n    \"\"\"\n    Train the model and evaluate on validation set with early stopping.\n    Enhanced progress bar shows all metrics in real-time.\n    \"\"\"\n    best_val_metrics = {'f1_score': 0}\n    train_metrics_history = []\n    val_metrics_history = []\n    \n    # Early stopping setup\n    best_val_f1 = 0\n    epochs_without_improvement = 0\n    start_epoch = 0\n\n    if resume_from is not None and os.path.exists(resume_from):\n        print(f\"Loading checkpoint from {resume_from}\")\n        checkpoint = torch.load(resume_from, map_location=device)\n        model.load_state_dict(checkpoint['model_state_dict'])\n        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n        start_epoch = checkpoint['epoch'] + 1  # Start from the next epoch\n        if 'best_val_f1' in checkpoint:\n            best_val_f1 = checkpoint['best_val_f1']\n        if 'train_metrics_history' in checkpoint:\n            train_metrics_history = checkpoint['train_metrics_history']\n        if 'val_metrics_history' in checkpoint:\n            val_metrics_history = checkpoint['val_metrics_history']\n        print(f\"Resuming from epoch {start_epoch} with validation F1: {best_val_f1:.4f}\")\n    \n    # For tracking GPU memory\n    if device.type == 'cuda':\n        start_gpu_memory = torch.cuda.memory_allocated(device) / (1024 ** 2)  # MB\n        print(f\"Initial GPU memory usage: {start_gpu_memory:.2f} MB\")\n    \n    # Learning rate scheduler\n    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n        optimizer, mode='max', factor=0.5, patience=2, verbose=True\n    )\n    \n    # Use scaler for mixed precision training if using GPU\n    scaler = torch.amp.GradScaler('cuda')\n    \n    for epoch in range(start_epoch, num_epochs):\n        epoch_start_time = time.time()\n        \n        # Training phase\n        model.train()\n        train_loss = 0.0\n        train_preds = []\n        train_labels = []\n        \n        # Progress bar for training\n        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Train]\")\n        \n        # Running metrics for progress bar\n        running_train_metrics = {\n            'loss': 0.0,\n            'acc': 0.0,\n            'prec': 0.0,\n            'rec': 0.0,\n            'spec': 0.0,\n            'f1': 0.0\n        }\n        samples_seen = 0\n        \n        for sequences, seq_lengths, labels in progress_bar:\n            batch_size = labels.size(0)\n            samples_seen += batch_size\n            \n            # Move data to device\n            sequences = sequences.to(device, non_blocking=True)\n            seq_lengths = seq_lengths.to(device, non_blocking=True)\n            labels = labels.to(device, non_blocking=True)\n            \n            # Forward pass with mixed precision if on GPU\n            optimizer.zero_grad()\n            \n            if scaler is not None:\n                with torch.amp.autocast('cuda'):\n                    logits = model(sequences, seq_lengths)\n                    loss = criterion(logits, labels)\n                \n                # Backward pass with gradient scaling\n                scaler.scale(loss).backward()\n                scaler.step(optimizer)\n                scaler.update()\n            else:\n                # Standard training path\n                logits = model(sequences, seq_lengths)\n                loss = criterion(logits, labels)\n                loss.backward()\n                optimizer.step()\n            \n            # Store predictions and true labels\n            train_loss += loss.item()\n            with torch.no_grad():\n                preds = (torch.sigmoid(logits) >= 0.5).float()\n            \n            # Convert to CPU numpy for metric calculation\n            batch_preds = preds.cpu().numpy()\n            batch_labels = labels.cpu().numpy()\n            train_preds.extend(batch_preds)\n            train_labels.extend(batch_labels)\n            \n            # Calculate batch metrics for progress bar update\n            batch_metrics = calculate_metrics(batch_labels, batch_preds)\n            \n            # Update running metrics for progress bar (weighted average based on batch size)\n            running_train_metrics['loss'] = (running_train_metrics['loss'] * (samples_seen - batch_size) + loss.item() * batch_size) / samples_seen\n            running_train_metrics['acc'] = (running_train_metrics['acc'] * (samples_seen - batch_size) + batch_metrics['accuracy'] * batch_size) / samples_seen\n            running_train_metrics['prec'] = (running_train_metrics['prec'] * (samples_seen - batch_size) + batch_metrics['precision'] * batch_size) / samples_seen\n            running_train_metrics['rec'] = (running_train_metrics['rec'] * (samples_seen - batch_size) + batch_metrics['recall'] * batch_size) / samples_seen\n            running_train_metrics['spec'] = (running_train_metrics['spec'] * (samples_seen - batch_size) + batch_metrics['specificity'] * batch_size) / samples_seen\n            running_train_metrics['f1'] = (running_train_metrics['f1'] * (samples_seen - batch_size) + batch_metrics['f1_score'] * batch_size) / samples_seen\n            \n            # Update progress bar with all metrics\n            progress_bar.set_postfix({\n                'loss': f\"{running_train_metrics['loss']:.4f}\",\n                'acc': f\"{running_train_metrics['acc']:.4f}\",\n                'prec': f\"{running_train_metrics['prec']:.4f}\", \n                'rec': f\"{running_train_metrics['rec']:.4f}\",\n                'spec': f\"{running_train_metrics['spec']:.4f}\",\n                'f1': f\"{running_train_metrics['f1']:.4f}\"\n            })\n        \n        # Calculate final training metrics on all data\n        train_metrics = calculate_metrics(train_labels, train_preds)\n        train_metrics['loss'] = train_loss / len(train_loader)\n        train_metrics_history.append(train_metrics)\n        \n        # Validation phase\n        model.eval()\n        val_loss = 0.0\n        val_preds = []\n        val_labels = []\n        \n        # Progress bar for validation\n        progress_bar = tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Val]\")\n        \n        # Running metrics for validation progress bar\n        running_val_metrics = {\n            'loss': 0.0,\n            'acc': 0.0,\n            'prec': 0.0,\n            'rec': 0.0,\n            'spec': 0.0,\n            'f1': 0.0\n        }\n        samples_seen = 0\n        \n        with torch.no_grad():\n            for sequences, seq_lengths, labels in progress_bar:\n                batch_size = labels.size(0)\n                samples_seen += batch_size\n                \n                # Move data to device\n                sequences = sequences.to(device, non_blocking=True)\n                seq_lengths = seq_lengths.to(device, non_blocking=True)\n                labels = labels.to(device, non_blocking=True)\n                \n                # Forward pass\n                logits = model(sequences, seq_lengths)\n                loss = criterion(logits, labels)\n                \n                # Store predictions and true labels\n                val_loss += loss.item()\n                preds = (torch.sigmoid(logits) >= 0.5).float()\n                \n                # Convert to CPU numpy for metric calculation\n                batch_preds = preds.cpu().numpy()\n                batch_labels = labels.cpu().numpy()\n                val_preds.extend(batch_preds)\n                val_labels.extend(batch_labels)\n                \n                # Calculate batch metrics for progress bar update\n                batch_metrics = calculate_metrics(batch_labels, batch_preds)\n                \n                # Update running metrics for progress bar (weighted average based on batch size)\n                running_val_metrics['loss'] = (running_val_metrics['loss'] * (samples_seen - batch_size) + loss.item() * batch_size) / samples_seen\n                running_val_metrics['acc'] = (running_val_metrics['acc'] * (samples_seen - batch_size) + batch_metrics['accuracy'] * batch_size) / samples_seen\n                running_val_metrics['prec'] = (running_val_metrics['prec'] * (samples_seen - batch_size) + batch_metrics['precision'] * batch_size) / samples_seen\n                running_val_metrics['rec'] = (running_val_metrics['rec'] * (samples_seen - batch_size) + batch_metrics['recall'] * batch_size) / samples_seen\n                running_val_metrics['spec'] = (running_val_metrics['spec'] * (samples_seen - batch_size) + batch_metrics['specificity'] * batch_size) / samples_seen\n                running_val_metrics['f1'] = (running_val_metrics['f1'] * (samples_seen - batch_size) + batch_metrics['f1_score'] * batch_size) / samples_seen\n                \n                # Update progress bar with all metrics\n                progress_bar.set_postfix({\n                    'loss': f\"{running_val_metrics['loss']:.4f}\",\n                    'acc': f\"{running_val_metrics['acc']:.4f}\",\n                    'prec': f\"{running_val_metrics['prec']:.4f}\", \n                    'rec': f\"{running_val_metrics['rec']:.4f}\",\n                    'spec': f\"{running_val_metrics['spec']:.4f}\",\n                    'f1': f\"{running_val_metrics['f1']:.4f}\"\n                })\n        \n        # Calculate validation metrics\n        val_metrics = calculate_metrics(val_labels, val_preds)\n        val_metrics['loss'] = val_loss / len(val_loader)\n        val_metrics_history.append(val_metrics)\n\n        # Save best model\n        torch.save({\n            'epoch': epoch,\n            'model_state_dict': model.state_dict(),\n            'optimizer_state_dict': optimizer.state_dict(),\n            'val_metrics': val_metrics,\n        }, 'model.pt')\n        print(f\"Saved model at epoch: {epoch}\")\n    \n        # Update learning rate based on validation F1 score\n        scheduler.step(val_metrics['f1_score'])\n        \n        # Check for early stopping\n        if val_metrics['f1_score'] > best_val_f1:\n            best_val_f1 = val_metrics['f1_score']\n            best_val_metrics = val_metrics\n            epochs_without_improvement = 0\n            # Save best model\n            torch.save({\n                'epoch': epoch,\n                'model_state_dict': model.state_dict(),\n                'optimizer_state_dict': optimizer.state_dict(),\n                'val_metrics': val_metrics,\n            }, 'best_line_classifier.pt')\n            print(f\"Saved best model with validation F1: {best_val_f1:.4f}\")\n        else:\n            epochs_without_improvement += 1\n            if epochs_without_improvement >= patience:\n                print(f\"Early stopping triggered after {epoch+1} epochs\")\n                break\n        \n        # Calculate epoch time\n        epoch_time = time.time() - epoch_start_time\n        \n        # Print progress\n        print(f\"Epoch {epoch+1}/{num_epochs} - Time: {epoch_time:.2f}s\")\n        print(f\"Train Loss: {train_metrics['loss']:.4f}, \"\n              f\"Accuracy: {train_metrics['accuracy']:.4f}, \"\n              f\"Precision: {train_metrics['precision']:.4f}, \"\n              f\"Recall: {train_metrics['recall']:.4f}, \"\n              f\"Specificity: {train_metrics['specificity']:.4f}, \"\n              f\"F1: {train_metrics['f1_score']:.4f}\")\n        print(f\"Val Loss: {val_metrics['loss']:.4f}, \"\n              f\"Accuracy: {val_metrics['accuracy']:.4f}, \"\n              f\"Precision: {val_metrics['precision']:.4f}, \"\n              f\"Recall: {val_metrics['recall']:.4f}, \"\n              f\"Specificity: {val_metrics['specificity']:.4f}, \"\n              f\"F1: {val_metrics['f1_score']:.4f}\")\n        \n        # Track GPU memory usage\n        if device.type == 'cuda':\n            current_gpu_memory = torch.cuda.memory_allocated(device) / (1024 ** 2)  # MB\n            max_gpu_memory = torch.cuda.max_memory_allocated(device) / (1024 ** 2)  # MB\n            print(f\"GPU Memory: Current {current_gpu_memory:.2f} MB, Max {max_gpu_memory:.2f} MB\")\n            # Reset peak memory stats for next epoch\n            torch.cuda.reset_peak_memory_stats(device)\n    \n    print(\"Training complete!\")\n    print(\"Best validation metrics:\")\n    for metric, value in best_val_metrics.items():\n        print(f\"{metric}: {value:.4f}\")\n    \n    return train_metrics_history, val_metrics_history\n\n\ndef main():\n    # Set random seeds for reproducibility\n    torch.manual_seed(42)\n    np.random.seed(42)\n    \n    # Check CUDA availability and set device\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    print(f\"Using device: {device}\")\n    \n    if device.type == 'cuda':\n        # Print GPU info\n        print(f\"GPU Device: {torch.cuda.get_device_name(0)}\")\n        print(f\"CUDA Version: {torch.version.cuda}\")\n        # Set CUDA optimizations\n        torch.backends.cudnn.benchmark = True\n        print(f\"CuDNN Enabled: {torch.backends.cudnn.enabled}\")\n        print(f\"CuDNN Version: {torch.backends.cudnn.version()}\")\n        # Set initial GPU memory\n        torch.cuda.empty_cache()\n        print(f\"Initial GPU Memory: {torch.cuda.memory_allocated(0)/(1024**2):.2f} MB\")\n    \n    # Create datasets\n    train_dataset = LineSequenceDataset(\"/kaggle/input/data1002/train.txt\")\n    \n    val_dataset = LineSequenceDataset(\"/kaggle/input/data1002/val.txt\")\n    \n    # test_dataset = LineSequenceDataset()\n    \n    # Calculate number of workers based on CPU cores\n    num_workers = min(4, os.cpu_count() or 0)\n    print(f\"Using {num_workers} worker threads for data loading\")\n    \n    # Create data loaders with pinned memory for faster GPU transfer\n    train_loader = DataLoader(\n        train_dataset, \n        batch_size=32, \n        shuffle=True, \n        collate_fn=collate_fn,\n        num_workers=num_workers,\n        pin_memory=device.type == 'cuda'\n    )\n    \n    val_loader = DataLoader(\n        val_dataset, \n        batch_size=32, \n        shuffle=False, \n        collate_fn=collate_fn,\n        num_workers=num_workers,\n        pin_memory=device.type == 'cuda'\n    )\n    \n    # test_loader = DataLoader(\n    #     test_dataset, \n    #     batch_size=32, \n    #     shuffle=False, \n    #     collate_fn=collate_fn,\n    #     num_workers=num_workers,\n    #     pin_memory=device.type == 'cuda'\n    # )\n    \n    # Initialize model and move to device\n    model = LineSequenceClassifier(\n        line_dim=4,\n        d_model=128,\n        nhead=8,\n        num_encoder_layers=4,\n        dim_feedforward=512,\n        dropout=0.1\n    ).to(device)\n    \n    # Print model summary\n    num_params = sum(p.numel() for p in model.parameters())\n    print(f\"Model has {num_params:,} parameters\")\n    \n    # Define loss function and optimizer\n    criterion = nn.BCEWithLogitsLoss()\n    optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.01)\n    \n    # Train model\n    print(\"Starting training...\")\n    train_metrics_history, val_metrics_history = train(\n        model, train_loader, val_loader, criterion, optimizer, device, num_epochs=2, patience=10, resume_from=\"/kaggle/input/model107/pytorch/default/1/best_line_classifier.pt\"\n    )\n    \n    # # Load best model\n    # checkpoint = torch.load('best_line_classifier.pt', map_location=device)\n    # model.load_state_dict(checkpoint['model_state_dict'])\n    # best_epoch = checkpoint['epoch']\n    # print(f\"Loaded best model from epoch {best_epoch+1}\")\n    \n    # # Evaluate on test set\n    # model.eval()\n    # test_preds = []\n    # test_labels = []\n    # test_loss = 0.0\n    \n    # progress_bar = tqdm(test_loader, desc=\"Evaluating on test set\")\n    \n    # with torch.no_grad():\n    #     for sequences, seq_lengths, labels in progress_bar:\n    #         # Move data to device\n    #         sequences = sequences.to(device, non_blocking=True)\n    #         seq_lengths = seq_lengths.to(device, non_blocking=True)\n    #         labels = labels.to(device, non_blocking=True)\n            \n    #         # Forward pass\n    #         logits = model(sequences, seq_lengths)\n    #         loss = criterion(logits, labels)\n    #         test_loss += loss.item()\n            \n    #         # Store predictions and true labels\n    #         preds = (torch.sigmoid(logits) >= 0.5).float()\n    #         test_preds.extend(preds.cpu().numpy())\n    #         test_labels.extend(labels.cpu().numpy())\n            \n    #         # Update progress bar\n    #         progress_bar.set_postfix({'loss': f\"{loss.item():.4f}\"})\n    \n    # # Calculate and print test metrics\n    # test_metrics = calculate_metrics(test_labels, test_preds)\n    # test_metrics['loss'] = test_loss / len(test_loader)\n    # print(\"\\nTest metrics:\")\n    # for metric, value in test_metrics.items():\n    #     print(f\"{metric}: {value:.4f}\")\n    \n    \n    # Clean up\n    if device.type == 'cuda':\n        torch.cuda.empty_cache()\n\n\nif __name__ == \"__main__\":\n    import os\n    main()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-07T16:07:58.981359Z","iopub.execute_input":"2025-03-07T16:07:58.981683Z","execution_failed":"2025-03-07T16:09:34.961Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\nGPU Device: Tesla P100-PCIE-16GB\nCUDA Version: 12.1\nCuDNN Enabled: True\nCuDNN Version: 90100\nInitial GPU Memory: 41.65 MB\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-5-800b125db868>:312: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  checkpoint = torch.load(resume_from, map_location=device)\n/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Using 4 worker threads for data loading\nModel has 819,809 parameters\nStarting training...\nLoading checkpoint from /kaggle/input/model107/pytorch/default/1/best_line_classifier.pt\nResuming from epoch 1 with validation F1: 0.0000\nInitial GPU memory usage: 41.65 MB\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/2 [Train]:   0%|          | 189/136290 [00:31<5:59:10,  6.32it/s, loss=0.4061, acc=0.8191, prec=0.8108, rec=0.7910, spec=0.8415, f1=0.7948]","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}