{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import random\n",
    "\n",
    "\n",
    "class SceneDataset(Dataset):\n",
    "    def __init__(self, file_path, do_augmentation=True):\n",
    "        self.file_path = file_path\n",
    "        self.do_augmentation = do_augmentation\n",
    "        self.cache = []  # To store parsed scenes\n",
    "        self.samples = []  # To store indices of individual samples\n",
    "\n",
    "        # Read and parse the file during initialization\n",
    "        self._parse_file()\n",
    "\n",
    "    def _parse_file(self):\n",
    "        \"\"\"Reads the file and caches scenes and their queries.\"\"\"\n",
    "        with open(self.file_path, 'r') as file:\n",
    "            for line_idx, line in enumerate(file):\n",
    "                line = line.strip().split()\n",
    "\n",
    "                # Parse obstacles\n",
    "                obstacles = []\n",
    "                idx = 0\n",
    "                while idx < len(line) and line[idx] == 'p':\n",
    "                    idx += 1  # Skip 'p'\n",
    "                    obstacle = []\n",
    "                    while idx < len(line) and line[idx] != 'p' and line[idx] != 'q':\n",
    "                        x, y = float(line[idx]), float(line[idx + 1])\n",
    "                        obstacle.append((x, y))\n",
    "                        idx += 2\n",
    "                    obstacles.append(obstacle)\n",
    "\n",
    "                # Parse queries and labels\n",
    "                queries = []\n",
    "                while idx < len(line):\n",
    "                    if line[idx] == 'q':\n",
    "                        idx += 1  # Skip 'q'\n",
    "                        query = []\n",
    "                        for _ in range(2):  # Each query has 2 coordinate pairs\n",
    "                            x, y = float(line[idx]), float(line[idx + 1])\n",
    "                            query.append((x, y))\n",
    "                            idx += 2\n",
    "                        label = int(line[idx])  # Label follows the query\n",
    "                        idx += 1\n",
    "                        queries.append((query, label))\n",
    "\n",
    "                # Cache the parsed scene\n",
    "                scene_idx = len(self.cache)\n",
    "                self.cache.append((obstacles, queries))\n",
    "\n",
    "                # Index individual samples\n",
    "                for query_idx in range(len(queries)):\n",
    "                    self.samples.append((scene_idx, query_idx))\n",
    "\n",
    "    def _generate_vertex_order(self, vertices):\n",
    "        \"\"\"Generates cyclic random orders for vertices.\"\"\"\n",
    "        n = len(vertices)\n",
    "        orders = []\n",
    "        r = 1\n",
    "        if self.do_augmentation:\n",
    "            r = 2\n",
    "        for _ in range(r):\n",
    "            start_idx = random.randint(0, n - 1)\n",
    "            orders.append(list(range(start_idx, n)) + list(range(0, start_idx)))\n",
    "        return orders\n",
    "\n",
    "    def _generate_obstacle_order(self, num_obstacles, num_order):\n",
    "        \"\"\"Generates random orders for obstacles.\"\"\"\n",
    "        orders = []\n",
    "        if not self.do_augmentation:\n",
    "            num_order = 1\n",
    "        for _ in range(num_order):\n",
    "            orders.append(random.sample(range(num_obstacles), num_obstacles))\n",
    "        return orders\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Total number of samples (queries).\"\"\"\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Returns a single sample: obstacles, query, label, and augmentation orders.\"\"\"\n",
    "        scene_idx, query_idx = self.samples[idx]\n",
    "        obstacles, queries = self.cache[scene_idx]\n",
    "        query, label = queries[query_idx]\n",
    "\n",
    "        # Generate augmentation orders\n",
    "        vertex_orders = [self._generate_vertex_order(obstacle) for obstacle in obstacles]\n",
    "        obstacle_order = self._generate_obstacle_order(len(obstacles),3)\n",
    "\n",
    "        return {\n",
    "            'obstacles': obstacles,        # Original obstacle coordinates\n",
    "            'query': query,                # Original query coordinates\n",
    "            'label': label,                # Binary label (0 or 1)\n",
    "            'vertex_orders': vertex_orders, # Vertex augmentation orders per obstacle\n",
    "            'obstacle_order': obstacle_order # Obstacle augmentation orders\n",
    "        }\n",
    "\n",
    "# Custom collate function for batching\n",
    "def collate_fn(batch):\n",
    "    \"\"\"Prepares a batch by grouping obstacles, queries, labels, and orders.\"\"\"\n",
    "    obstacle_batch = []\n",
    "    query_batch = []\n",
    "    label_batch = []\n",
    "    vertex_orders_batch = []\n",
    "    obstacle_orders_batch = []\n",
    "\n",
    "    for item in batch:\n",
    "        obstacle_batch.append(item['obstacles'])\n",
    "        query_batch.append(item['query'])\n",
    "        label_batch.append(item['label'])\n",
    "        vertex_orders_batch.append(item['vertex_orders'])\n",
    "        obstacle_orders_batch.append(item['obstacle_order'])\n",
    "\n",
    "    return {\n",
    "        'obstacles': obstacle_batch,          # List of obstacles for each sample\n",
    "        'queries': query_batch,               # List of queries for each sample\n",
    "        'labels': torch.tensor(label_batch, dtype=torch.float),  # Labels as tensor\n",
    "        'vertex_orders': vertex_orders_batch, # Vertex augmentation orders\n",
    "        'obstacle_orders': obstacle_orders_batch # Obstacle augmentation orders\n",
    "    }\n",
    "\n",
    "\n",
    "train_dataset = SceneDataset(\"/kaggle/input/data0007/train_3500.txt\")\n",
    "val_dataset = SceneDataset(\"/kaggle/input/data0001/val_50.txt\",do_augmentation=False)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
